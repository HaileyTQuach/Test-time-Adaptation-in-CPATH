{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pariyamd/CPATH_TTA/blob/main/Project_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EySskOjODQcv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zE89CBdCEGD6",
    "outputId": "ff7b2e44-a8d4-418e-ad78-dcaefdadf7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A77drYSHD-mT",
    "outputId": "749b4588-aea5-4875-9aa9-c90a1b7fc32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/COMP499/Project/Training data\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/COMP499/Project/Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4MQaaOHAEzAC"
   },
   "outputs": [],
   "source": [
    "!tar -xf 02_training_native.tar -C \"/content/drive/MyDrive/COMP499/Project/Training data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOHu7yviPkKi",
    "outputId": "40c408f0-26f4-481d-e406-3875cdeac5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Import ResNet50 architecture with ImageNet weights\n",
    "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(350,350,3))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Make the convolutional base trainable\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "# Adjust layer names based on the ResNet50 architecture\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'conv5_block1_2_conv' or layer.name == 'conv5_block1_1_conv':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iokWtMd1QsLU",
    "outputId": "be3ada0c-cc81-4d7f-ec73-25f3eb2f66b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120000 images belonging to 3 classes.\n",
      "Epoch 1/7\n",
      "1200/1200 [==============================] - 1706s 1s/step - loss: 0.6523 - acc: 0.7146\n",
      "Epoch 2/7\n",
      "1200/1200 [==============================] - 1066s 888ms/step - loss: 0.5417 - acc: 0.7671\n",
      "Epoch 3/7\n",
      "1200/1200 [==============================] - 1084s 903ms/step - loss: 0.5013 - acc: 0.7868\n",
      "Epoch 4/7\n",
      "1200/1200 [==============================] - 1059s 882ms/step - loss: 0.4720 - acc: 0.8013\n",
      "Epoch 5/7\n",
      "1200/1200 [==============================] - 1045s 871ms/step - loss: 0.4515 - acc: 0.8110\n",
      "Epoch 6/7\n",
      "1200/1200 [==============================] - 1074s 895ms/step - loss: 0.4321 - acc: 0.8209\n",
      "Epoch 7/7\n",
      "1200/1200 [==============================] - 1064s 886ms/step - loss: 0.4130 - acc: 0.8294\n"
     ]
    }
   ],
   "source": [
    "#folder with training dataset\n",
    "train_dir = '/content/drive/MyDrive/COMP499/Project/Training data/02_training_native'\n",
    "\n",
    "# Data generator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "#Augmentation: horizontal and vertical flips\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(350,350),\n",
    "        batch_size=100,\n",
    "        class_mode='categorical')\n",
    "\n",
    "#train for 7 Epochs\n",
    "history = model.fit(train_generator, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yKo_Jgs94ewY"
   },
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "model.save_weights('/content/drive/MyDrive/COMP499/Project/TvN_350_SN_D256_Initial_Ep7.weights')\n",
    "model.save('/content/drive/MyDrive/COMP499/Project/TvN_350_SN_D256_Initial_Ep7.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wLwlWw6wZqT9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import Session, ConfigProto, GPUOptions\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "# Clear TensorFlow session to free up GPU memory\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(Session(config=config))\n",
    "\n",
    "# After clearing, reset Keras session\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SFKU9qba7SO6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Clear PyTorch's CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LrzI0nQ5rTA"
   },
   "source": [
    "## TRAIN IN PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yG9R2WGf5teM",
    "outputId": "9f11b019-e0f9-4312-9fdb-b5adb3eb7013"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/7: 100%|██████████| 1200/1200 [36:01<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Loss: 0.8583, Accuracy: 79.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/7: 100%|██████████| 1200/1200 [28:24<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/7], Loss: 0.6809, Accuracy: 91.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/7: 100%|██████████| 1200/1200 [28:25<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/7], Loss: 0.6453, Accuracy: 93.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/7: 100%|██████████| 1200/1200 [28:37<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/7], Loss: 0.6260, Accuracy: 95.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/7: 100%|██████████| 1200/1200 [28:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/7], Loss: 0.6139, Accuracy: 95.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/7: 100%|██████████| 1200/1200 [27:51<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/7], Loss: 0.6063, Accuracy: 96.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/7: 100%|██████████| 1200/1200 [27:45<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/7], Loss: 0.6010, Accuracy: 96.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the ResNet50 model pre-trained on ImageNet\n",
    "conv_base = models.resnet50(weights='DEFAULT')\n",
    "\n",
    "# Since we're using include_top=False in Keras, we'll replace the FC layers ourselves\n",
    "num_ftrs = conv_base.fc.in_features  # Get number of features in last layer\n",
    "conv_base.fc = nn.Sequential(  # Replace the fully connected layer\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(num_ftrs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 3),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "conv_base = conv_base.to(device)  # Move model to GPU if available\n",
    "\n",
    "# Freeze all layers except 'layer4[0].conv1'\n",
    "# Make the convolutional base trainable and unfreeze layers after 'layer4[0].conv1'\n",
    "for name, child in conv_base.named_children():\n",
    "    if name in ['layer4']:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((350, 350)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Assuming '/content/drive/MyDrive/COMP499/Project/Training data/02_training_native' is your training directory\n",
    "train_dataset = ImageFolder(root='/content/drive/MyDrive/COMP499/Project/Training data/02_training_native', transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(conv_base.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 7\n",
    "for epoch in range(num_epochs):\n",
    "    conv_base.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "    for batch_idx, (inputs, labels) in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the configured device\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = conv_base(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_preds += labels.size(0)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct_preds / total_preds\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ywv04wC07V-f"
   },
   "outputs": [],
   "source": [
    "torch.save(conv_base, '/content/drive/MyDrive/COMP499/Project/TvN_350_SN_D256_Initial_Ep7_fullmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-4eM8ScFuhUp"
   },
   "outputs": [],
   "source": [
    "# Clear PyTorch's CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xEeOY9s4vC5K",
    "outputId": "785370f5-9505-49eb-e9f2-1039f5aa0eec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/7: 100%|██████████| 1200/1200 [30:38<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch, Loss: 0.5968, Accuracy: 96.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##Consecutive stepwise release of further convolutional layers\n",
    "# v2, Layers 3, 4 free\n",
    "conv_base.train()\n",
    "\n",
    "for name, child in conv_base.named_children():\n",
    "    if name == 'layer3':\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# Update the optimizer to include the newly unfrozen parameters\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, conv_base.parameters()), lr=1e-6)\n",
    "\n",
    "# Continue training or fine-tuning\n",
    "for epoch in range(1):  # Fine-tune for 1 epoch\n",
    "    conv_base.train()  # Ensure the model is in training mode\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "    for batch_idx, (inputs, labels) in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the configured devic\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = conv_base(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_preds += labels.size(0)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "    # Compute loss and accuracy\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct_preds / total_preds\n",
    "    print(f'Fine-tune Epoch, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bITTWsafwlL6"
   },
   "outputs": [],
   "source": [
    "torch.save(conv_base, '/content/drive/MyDrive/COMP499/Project/Models/TvN_350_SN_D256_v2_Ep1_fullmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPXKegZk3v7S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM2WW1PY3BBJbQBs+3PtRT8",
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (pathology)",
   "language": "python",
   "name": "pathology"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
